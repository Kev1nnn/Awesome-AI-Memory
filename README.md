# Awesome-AI-Memory

[![Awesome](https://awesome.re/badge.svg)](https://github.com/zjunlp/ModelEditingPapers) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
![](https://img.shields.io/badge/PRs-Welcome-red)


## ğŸ‘‹ Introduction
Large Language Models (LLMs) have rapidly evolved into powerful general-purpose reasoning and generation engines. Nevertheless, despite their continuously advancing capabilities, LLMs remain fundamentally constrained by a critical limitation: the finite length of their context window. This constraint defines the scope of information directly accessible during a single inference process, endowing models with only short-term memory capabilities. Consequently, they struggle to support extended conversations, personalized interactions, continuous learning, and complex multi-stage tasks.

To transcend the inherent limitations of context windows, AI memory and memory systems for LLMs have emerged as a vital and active research and engineering frontier. By introducing external, persistent, and controllable memory structures beyond model parameters, these systems enable large models to store, retrieve, compress, and manage historical information during generation processes. This capability allows models to continuously leverage long-term experiences within limited context windows, achieving cross-session consistency and continuous reasoning abilities.

Awesome-AI-Memory is a comprehensive repository dedicated to AI memory and memory systems for large language models, systematically curating relevant research papers, framework tools, and practical implementations. This repository endeavors to map the rapidly evolving research landscape in LLM memory systems, bridging multiple disciplines including natural language processing, information retrieval, intelligent agent systems, and cognitive science.

---

## ğŸ¯ Goal of Repository
Our mission is to establish a centralized, continuously evolving knowledge base that serves as a valuable reference for researchers and practitioners, ultimately accelerating the development of intelligent systems capable of long-term memory retention, sustained reasoning, and adaptive evolution over time.

---

## ğŸ“ Project Scope
This repository focuses on memory mechanisms and system designs that extend or augment the context window capabilities of large language models, rather than merely addressing model pre-training or general knowledge learning. The content encompasses both theoretical research and engineering practices.

ğŸŒ€ Included Content (In Scope)
- Memory and memory system designs for large language models
- External explicit memory beyond model parameters
- Short-term memory, long-term memory, episodic memory, and semantic memory
- Retrieval-Augmented Generation (RAG) as a memory access mechanism
- Memory management strategies (writing, updating, forgetting, compression)
- Memory systems in intelligent agents (Agents)
- Shared and collaborative memory in multi-agent systems
- Memory models inspired by cognitive science and biological memory
- Evaluation methods, benchmarks, and datasets related to LLM memory
- Open-source frameworks and tools for memory-enhanced LLMs

ğŸŒ€ Excluded Content (Out of Scope)
- General model pre-training or scaling research without direct memory relevance
- Purely parameterized knowledge learning without memory interaction
- Traditional databases or information retrieval systems unrelated to LLMs
- Generic memory systems outside the LLM context (unless demonstrating direct transfer value)

---

<!-- ## ğŸ—‚ï¸ AI-Memory Taxonomy

To systematically organize the diverse research and practical resources in the field of AI large model memory, this repository categorizes memory systems across multiple orthogonal dimensions, reflecting variations in storage methods, temporal scales, content forms, operational processes, and system architectures.
1. Memory by Storage Location
- Parametric Memory
  - Knowledge implicitly encoded within model weights
  - Static and not directly editable during inference
- External / Explicit Memory
  - Memory stored outside model parameters
  - Readable, writable, and dynamically updatable
2. Memory by Temporal Scope
- Short-Term Memory
  - Entirely dependent on context window
  - Session-level, temporary information
- Long-Term Memory
  - Persistent memory across sessions and time scales
  - Supports long-term consistency and personalization
3. Memory by Content Type
- Episodic Memory
  - Event-based historical interaction memory
  - Preserves temporal sequence and contextual relationships
- Semantic Memory
  - Facts, rules, and preferences abstracted from multiple experiences
  - Typically derived from compression or induction of episodic memory
- Procedural Memory
  - Memory related to action patterns, skills, and task execution strategies
4. Memory Operations
- Writing: Determining which information should be stored
- Retrieval: Selecting relevant memories for current tasks
- Updating: Correcting or merging existing memories
- Forgetting: Removing or weakening low-value information
- Compression: Summarizing historical information to fit context windows
5. Memory Mechanisms & Architectures
- Retrieval-Augmented Generation (RAG)
- Summary-based memory mechanisms
- Vectorized semantic retrieval
- Symbolic-neural hybrid memory systems
- Event-driven and trigger-based memory mechanisms
- Reinforcement learning-based memory strategy optimization
6. Memory in Agent Systems
- Single-agent memory
- Multi-agent shared memory
- Tool-augmented memory
- Planning-aware memory
- Personality and emotion-related memory
7. Evaluation & Benchmarks
- Long-term consistency evaluation
- Continuous interaction and long-term task benchmarks
- Memory recall and utilization efficiency metrics
- Personalization and user preference retention evaluation

--- -->

## ğŸ”” News

+ 2025-12-10 â€“ ğŸ‰ Initial Repo
+ 2025-07-04 â€“ ğŸ‰ MemOS Paper Released: MemOS: A Memory OS for AI System was published on arXiv.
+ 2025-05-28 â€“ ğŸ‰ Short Paper Uploaded: MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models was published on arXiv.
+ 2024-07-01 â€“ ğŸ‰ Memory3 Paper Released: Memory3: Language Modeling with Explicit Memory introduces the new approach to structured memory in LLMs.

---

ğŸ—ºï¸ Table of Contents
- [Introduction](#introduction)
- [Goal of Repository](#goal-of-repository)
- [Project Scope](#project-scope)
- [News](#news)
- [Introduction of Core Concept](#introduction-of-core-concept)
- [Paper List](#paper-list)
  - [Survey](#survey)
  - [Framework & Methods](#framework--methods)
  - [Benchmark & Datasets](#benchmark--datasets)
  - [Memory Evaluation](#memory-evaluation)
  - [System & model](#system--model)
- [Resource](#resource)
  - [Benchmarks and tasks](#benchmarks-and-tasks)
  - [Systems and open sources](#systems-and-open-sources)
  - [Star Trends](#star-trends)

---

## ğŸ§  Core Concepts

- LLM Memory: A fusion of implicit knowledge encoded within parameters (acquired during training) and explicit storage outside parameters (retrieved at runtime), enabling models to transcend token limitations and possess human-like abilities to "remember the past, understand the present, and predict the future."

- Memory System: The complete technical stack implementing memory functionality for large language models, comprising four core components:
  - Memory Storage Layer: Vector databases (e.g., Chroma, Weaviate), graph databases, or hybrid storage solutions
  - Memory Processing Layer: Embedding models, summarization generators, and memory segmenters
  - Memory Retrieval Layer: Multi-stage retrievers, reranking modules, and context injectors
  - Memory Control Layer: Memory prioritization managers, forgetting controllers, and consistency coordinators

- Memory Operations: Atomic memory operations executed through tool calling in memory systems:
  - Writing: Converting dialogue content into vectors for storage, often combined with summarization to reduce noise
  - Retrieval: Generating queries based on current context to obtain Top-K relevant memories
  - Updating: Finding relevant memories via vector similarity and replacing or enhancing them
  - Deletion: Removing specific memories based on user instructions or automatic policies (e.g., privacy expiration)
  - Compression: Merging multiple related memories into summaries to free storage space

- Memory Management: The methodology for managing memories within memory systems, including:
  - Memory Lifecycle: End-to-end management from creation, active usage, infrequent access, to archiving/deletion
  - Conflict Resolution: Arbitration mechanisms for contradictory information (e.g., timestamp priority, source credibility weighting)
  - Resource Budgeting: Allocating memory quotas to different users/tasks to prevent resource abuse
  - Security Governance: Automatic detection and de-identification of PII (Personally Identifiable Information)

- Memory Classification: A multi-dimensional classification system unique to memory systems:
  - By Access Frequency: Working memory (current tasks), frequent memory (personal preferences), archived memory (historical records)
  - By Structured Degree: Structured memory (database records), semi-structured memory (dialogue summaries), unstructured memory (raw conversations)
  - By Sharing Scope: Personal memory (single user), team memory (collaborative spaces), public memory (shared knowledge bases)
  - By Temporal Validity: Permanent memory (core facts), temporary memory (conversation context), time-sensitive memory (e.g., "user is in a bad mood today")

- Memory Mechanisms: Core technical components enabling memory system functionality:
  - Retrieval-Augmented Generation (RAG): Enhancing generation by retrieving relevant information from knowledge bases
  - Memory Reflection Loop: Models periodically "review" conversation history to generate high-level summaries
  - Memory Routing: Automatically selecting retrieval sources based on query type (personal memory/public knowledge base)

- Explicit Memory: Memory stored as raw text outside the model, implemented through vector databases with hybrid indexing strategies:
  - Dense Vector Indexing: Handling semantic similarity queries
  - Sparse Keyword Indexing: Processing exact match queries
  - Multi-vector Indexing: Segmenting long documents into multiple parts, each independently indexed

- Parametric Memory: Knowledge and capabilities stored within the fixed weights of a language model's architecture, characterized by:
  - Serving as the model's core long-term semantic memory carrier
  - Being activatable without external retrieval or explicit contextual support
  - Providing the foundational capability for zero-shot reasoning, general responses, and language generation

- Long-Term Memory: Key information designed for persistent storage, typically implemented as external knowledge bases with capabilities including:
  - Automatic Summarization: Distilling multi-turn dialogues into structured memory
  - Context Binding: Recording memory context to prevent erroneous generalization
  - Multimodal Storage: Simultaneously preserving text, images, audio, and other multimodal memories

- Short-Term Memory: Active information within the LLM's context window, constrained by attention mechanisms. Key techniques include:
  - KV Cache Management: Reusing key-value caches to reduce redundant computation
  - Context Compression: Using summaries instead of detailed history (e.g., "the previous 5 dialogue rounds discussed project budget")
  - Sliding Window Attention: Focusing only on the most recent N tokens while preserving special markers
  - Memory Summary Injection: Dynamically inserting summaries of long-term memory into short-term context

- Episodic Memory: Memory type recording specific user interaction history, fundamental to personalized AI:
  - User Identity Recognition: Identifying the same user across sessions
  - Interaction Trajectory Recording: Preserving user decision paths and feedback
  - Emotional State Tracking: Recording patterns of user mood changes
  - Preference Evolution Modeling: Capturing long-term changes in user interests

- Memory Forgetting: Deliberately designed forgetting mechanisms in large models, including:
  - Selective Forgetting (Machine Unlearning): Removing the influence of specific information from training data, such as covering specific knowledge with forgetting layers
  - Privacy-Driven Forgetting: Automatically identifying and deleting PII information, or setting automatic expiration
  - Memory Decay: Automatically lowering the priority of infrequently accessed memories based on usage frequency
  - Conflict-Driven Forgetting: Strategically updating or discarding old memories when new evidence conflicts with them

- Memory Retrieval: The complex process of precisely locating relevant information from massive memory repositories:
  - Semantic Pre-filtering: Vector similarity matching to obtain Top-100 candidates
  - Contextual Reranking: Reordering results based on current query context
  - Temporal Filtering: Prioritizing the most recent relevant information

- Memory Compression: A collection of techniques maximizing memory utility under limited resources:
  - Content-level Compression: Extracting core information while discarding redundant details
  - Representation-level Compression: Vector quantization (e.g., PQ coding), dimensionality reduction
  - Organization-level Compression: Clustering similar memories, building hierarchical memory structures
  - Knowledge Distillation: Transferring key patterns from external memory into parametric memory

---

## ğŸ“š Paper List
Papers below are ordered by **publication date**:

<details>
  <summary><strong>Survey</strong></summary>

  <table style="width: 100%;">
    <tr>
      <td><strong>Date</strong></td>
      <td><strong>Paper & Summary</strong></td>
      <td><strong>Tags</strong></td>
      <td><strong>Links</strong></td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-09-18</td>
      <td style="width: 55%;">
      <strong>A Survey of Machine Unlearning</strong></td>
      <td style="width: 15%;">
      <img src="https://img.shields.io/badge/Machine%20Forgetting-grey" alt="Machine Forgetting"></td>
      <td style="width: 15%;">
        <a href="https://dl.acm.org/doi/full/10.1145/3749987"><img src="https://img.shields.io/badge/ACM-Paper-black?labelColor=blue" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ·±å…¥æ¢è®¨äº†æœºå™¨é—å¿˜ï¼ˆmachine unlearningï¼‰çš„æ¦‚å¿µã€èƒŒæ™¯åŠå…¶åœ¨ç°ä»£æœºå™¨å­¦ä¹ ä¸­çš„é‡è¦æ€§.<br>
          â€¢ æœºå™¨é—å¿˜æ—¨åœ¨ä½¿å­¦ä¹ ç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆåˆ é™¤ç‰¹å®šæ•°æ®çš„å½±å“ï¼Œè€Œæ— éœ€è¿›è¡Œå…¨é¢çš„æ¨¡å‹é‡æ–°è®­ç»ƒ.<br>
          â€¢ è®ºæ–‡åˆ†æäº†æœºå™¨é—å¿˜çš„å¿…è¦æ€§ã€æŒ‘æˆ˜ã€è®¾è®¡è¦æ±‚ï¼Œä»¥åŠç›®å‰çš„ç ”ç©¶è¿›å±•ï¼ŒåŒæ—¶å¼ºè°ƒäº†è¯¥é¢†åŸŸåœ¨ç®—æ³•æœ‰æ•ˆæ€§ã€å…¬å¹³æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-09-02</td>
      <td style="width: 55%;">
      <strong>A Survey on the Memory Mechanism of Large Language Model based Agents</strong></td>
      <td style="width: 15%;">
      <img src="https://img.shields.io/badge/Memory%20Mechanisms-yellowgreen" alt="Memory Mechanisms Badge">
      <img src="https://img.shields.io/badge/Memory%20Modules-orange" alt="Memory Modules Badge">
      <td style="width: 15%;">
        <a href="https://dl.acm.org/doi/pdf/10.1145/3748302"><img src="https://img.shields.io/badge/ACM-Paper-black?labelColor=blue" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“çš„è®°å¿†æœºåˆ¶ï¼Œå¼ºè°ƒè®°å¿†åœ¨æ™ºèƒ½ä½“è‡ªæˆ‘è¿›åŒ–åŠå¤æ‚äº¤äº’ä¸­çš„é‡è¦æ€§.<br>
          â€¢ ç³»ç»Ÿæ€§åœ°æ€»ç»“å¹¶åˆ†ç±»å½“å‰çš„è®°å¿†æ¨¡å—è®¾è®¡å’Œè¯„ä¼°ï¼ŒåŒæ—¶åˆ†æäº†å…¶åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸­çš„ä½œç”¨åŠå±€é™æ€§.<br>
          â€¢ æ™ºèƒ½ä½“èƒ½å¤Ÿæ”¹è¿›å†³ç­–å’Œä»»åŠ¡å¤„ç†.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-05-31</td>
      <td style="width: 55%;">
      <strong>A Survey of Machine Unlearning in Large Language Models: Methods, Challenges and Future Directions</strong></td>
      <td style="width: 15%;">
      <img src="https://img.shields.io/badge/Machine%20Forgetting-grey" alt="Machine Forgetting"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2503.01854v2"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„æœºå™¨é—å¿˜ï¼ˆLLM unlearningï¼‰æŠ€æœ¯ï¼Œæ—¨åœ¨åœ¨ä¸å®Œå…¨é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆå»é™¤æ¨¡å‹ä¸­ä¸è‰¯æ•°æ®ï¼ˆå¦‚æ•æ„Ÿæˆ–éæ³•ä¿¡æ¯ï¼‰çš„å½±å“ï¼ŒåŒæ—¶ä¿æŒæ•´ä½“æ•ˆç”¨.<br>
          â€¢ å®šä¹‰äº†LLMé—å¿˜çš„ç›®æ ‡å’ŒèŒƒå¼ï¼Œå¹¶å»ºç«‹äº†å…¨é¢çš„åˆ†ç±»ä½“ç³».<br>
          â€¢ å›é¡¾äº†ç°æœ‰æ–¹æ³•ï¼Œè¯„ä¼°å…¶ä¼˜ç¼ºç‚¹ï¼Œå¹¶æ¢è®¨æœªæ¥ç ”ç©¶çš„æœºé‡.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-05-27</td>
      <td style="width: 55%;">
      <strong>Rethinking Memory in AI Taxonomy, Operations, Topics, and Future Directions</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/QA_Head-blue" alt="QA Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2505.00675"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ¢è®¨äº†äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä¸­æœ‰å…³è®°å¿†çš„å¤šç»´åº¦ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„è®°å¿†æ“ä½œåŠå…¶ç®¡ç†.<br>
          â€¢ å¯¹è®°å¿†è¡¨ç¤ºçš„å¤šç§ç±»å‹åŠæ“ä½œè¿›è¡Œåˆ†ç±»ï¼ŒåŒ…æ‹¬æ•´åˆã€æ›´æ–°ã€ç´¢å¼•ã€é—å¿˜ã€æ£€ç´¢å’Œå‹ç¼©ï¼Œç³»ç»ŸåŒ–åœ°åˆ†æäº†è®°å¿†åœ¨AIä¸­çš„é‡è¦æ€§ä¸å®ç°æ–¹å¼.<br>
          â€¢ å¯¹å¤§é‡æ–‡çŒ®çš„åˆ†æï¼Œè¯†åˆ«å‡ºé•¿æœŸè®°å¿†ã€å‚æ•°åŒ–è®°å¿†ã€é•¿ä¸Šä¸‹æ–‡è®°å¿†åŠå¤šæºè®°å¿†æ•´åˆç­‰å››ä¸ªå…³é”®ç ”ç©¶ä¸»é¢˜.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-04-24</td>
      <td style="width: 55%;">
      <strong>Cognitive Memory in Large Language Models</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Memory_Head-blue" alt="Memory Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2504.02441"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ å…¨é¢æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„è®°å¿†æœºåˆ¶ï¼Œé‡ç‚¹åˆ†æäº†ä¸åŒç±»å‹çš„è®°å¿†åŠå…¶åœ¨æ¨¡å‹ä¸­çš„ä½œç”¨.<br>
          â€¢ LLMsåœ¨ä¿¡æ¯æ£€ç´¢å’Œäº¤äº’æ€»ç»“æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é•¿æœŸè®°å¿†ä¸å¤Ÿç¨³å®š.<br>
          â€¢ å°†è®°å¿†æ•´åˆè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿå¯¹äºæä¾›ä¸°å¯Œçš„ä¸Šä¸‹æ–‡å“åº”ï¼Œå‡å°‘å¹»è§‰ç°è±¡ï¼Œæé«˜æ•°æ®å¤„ç†æ•ˆç‡ä»¥åŠæ¨åŠ¨AIç³»ç»Ÿè‡ªæˆ‘è¿›åŒ–è‡³å…³é‡è¦.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-04-23</td>
      <td style="width: 55%;"><strong>From Human Memory to AI Memory A Survey on Memory Mechanisms in the Era of LLMs </strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Arithmetic_Head-blue" alt="Arithmetic Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2504.15965"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ¢è®¨äººç±»è®°å¿†ä¸åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç³»ç»Ÿçš„è®°å¿†æœºåˆ¶ä¹‹é—´çš„å…³ç³».<br>
          â€¢ ä¸»è¦è´¡çŒ®åŒ…æ‹¬å¯¹LLMé©±åŠ¨AIç³»ç»Ÿçš„è®°å¿†è¿›è¡Œç³»ç»Ÿå®šä¹‰ï¼Œä¸äººç±»è®°å¿†å»ºç«‹è”ç³».<br>
          â€¢ è®ºæ–‡æå‡ºä¸€ç§åŸºäºå¯¹è±¡ã€å½¢å¼å’Œæ—¶é—´çš„ä¸‰ç»´è®°å¿†åˆ†ç±»æ–¹æ³•ï¼Œå¹¶æ€»ç»“å½“å‰ä¸ªäººè®°å¿†å’Œç³»ç»Ÿè®°å¿†ç ”ç©¶çš„å…³é”®é—®é¢˜.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-01-12</td>
      <td style="width: 55%;"><strong>Human-inspired Perspectives: A Survey on AI Long-term Memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Retrieval_Head-blue" alt="Retrieval Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2411.00489"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æœ¬æ–‡ç³»ç»Ÿæ€§æ¢è®¨äº†äººç±»é•¿æœŸè®°å¿†æœºåˆ¶ä¸AIé•¿æœŸè®°å¿†ä¹‹é—´çš„ç›¸äº’å…³ç³»ï¼Œå¹¶æå‡ºäº†ä¸€ç§è‡ªé€‚åº”é•¿æœŸè®°å¿†çš„è®¤çŸ¥æ¶æ„ï¼ˆSALMï¼‰.<br>
          â€¢ æ–‡ç« ä»‹ç»äº†äººç±»è®°å¿†çš„ç»“æ„ï¼ŒåŒ…æ‹¬æ„Ÿå®˜è®°å¿†ã€å·¥ä½œè®°å¿†åŠé•¿æœŸè®°å¿†çš„ä¸åŒç±»å‹ï¼ˆæƒ…èŠ‚è®°å¿†ã€è¯­ä¹‰è®°å¿†å’Œç¨‹åºè®°å¿†ï¼‰.<br>
          â€¢ æ–‡ç« åˆ†æäº†AIé•¿æœŸè®°å¿†çš„åˆ†ç±»ï¼ˆå‚æ•°åŒ–è®°å¿†ä¸éå‚æ•°åŒ–è®°å¿†ï¼‰åŠå…¶å­˜å‚¨ä¸æ£€ç´¢æœºåˆ¶.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-04-02</td>
      <td style="width: 55%;"><strong>Digital Forgetting in Large Language Models: A Survey of Unlearning Methods</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Retrieval_Head-blue" alt="Retrieval Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2404.02062"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a>
      </td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„æ•°å­—é—å¿˜åŠå…¶å»å­¦ä¹ æ–¹æ³•ï¼Œèšç„¦äºè§£å†³éšç§ã€ç‰ˆæƒå’Œç¤¾ä¼šä¼¦ç†ç­‰é—®é¢˜.<br>
          â€¢ æ–‡ä¸­è§£æäº†ä¸åŒç±»å‹çš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œä»¥åŠæ•°å­—é—å¿˜çš„å®ç°æ–¹æ³•ï¼Œå¦‚æ•°æ®é‡è®­ã€æœºå™¨é—å¿˜ã€æç¤ºå·¥ç¨‹ç­‰.<br>
          â€¢ é€šè¿‡â€œé—å¿˜ä¿è¯â€çš„æ¦‚å¿µï¼Œå¼ºè°ƒäº†ç²¾ç¡®ä¸è¿‘ä¼¼é—å¿˜çš„æœ‰æ•ˆæœºåˆ¶.
        </td>
    </tr>  
  </table>

</details>


<details>
  <summary><strong>Framework & Methods</strong></summary>

  <table style="width: 100%;">
    <tr>
      <td><strong>Date</strong></td>
      <td><strong>Paper & Summary</strong></td>
      <td><strong>Tags</strong></td>
      <td><strong>Links</strong></td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-10-10</td>
      <td style="width: 55%;"><strong>How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2505.16067"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„è®°å¿†ç®¡ç†åŠå…¶å¯¹é•¿æœŸæ€§èƒ½çš„å½±å“.<br>
          â€¢ è®ºæ–‡å‘ç°äº†é”™è¯¯ä¼ æ’­å’Œä¸å¯¹é½ç»éªŒé‡æ”¾çš„é—®é¢˜ï¼Œå¼ºè°ƒäº†é«˜è´¨é‡è®°å¿†çš„é‡è¦æ€§.<br>
          â€¢ æ¯”è¾ƒäº†å¤šç§è®°å¿†æ·»åŠ å’Œåˆ é™¤ç­–ç•¥ï¼Œå‘ç°é€‰æ‹©æ€§æ·»åŠ ç­–ç•¥åœ¨é•¿æœŸå­¦ä¹ ä¸­è¡¨ç°ä¼˜è¶Šï¼Œè€Œå†å²åˆ é™¤ç­–ç•¥åœ¨å‡å°‘ä½è´¨é‡è®°å¿†è®°å½•æ–¹é¢æ•ˆæœæ˜¾è‘—.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-09-11</td>
      <td style="width: 55%;"><strong>OpenUnlearning:Accelerating LLM unlearning via unified benchmarking of methods and metrics</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Detection_Head-blue" alt="Detection Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2506.12618"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ â€œOpenUnlearningâ€æ¡†æ¶ï¼Œæ—¨åœ¨æ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é—å¿˜ï¼ˆunlearningï¼‰ç ”ç©¶.<br>
          â€¢ OpenUnlearningæ•´åˆäº†å¤šç§å»å­¦ä¹ ç®—æ³•å’Œè¯„ä¼°æ–¹æ³•ï¼Œç®€åŒ–äº†é—å¿˜ç ”ç©¶çš„æµç¨‹.<br>
          â€¢ é€šè¿‡å…·æœ‰é’ˆå¯¹æ€§çš„è¯„ä¼°ï¼ŒOpenUnlearningç¡®ä¿å»å­¦ä¹ è¯„ä¼°æ ‡å‡†çš„å¯ä¿¡åº¦å’Œé²æ£’æ€§.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-07-27</td>
      <td style="width: 55%;"><strong>SynapticRAG:Enhancing temporal memory retrieval in large language models through synaptic mechanisms</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Direct_effect_Head-blue" alt="Direct Effect Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2025.findings-acl.1048.pdf"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ SynapticRAGæ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ–°å‹è®°å¿†æ£€ç´¢æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å…¶åœ¨è·¨ä¼šè¯å¯¹è¯ä¸­çš„è®°å¿†æ£€ç´¢èƒ½åŠ›.<br>
          â€¢ SynapticRAGé€šè¿‡ç»“åˆæ—¶é—´å…³è”è§¦å‘å’Œç”Ÿç‰©å¯å‘çš„çªè§¦ä¼ æ’­æœºåˆ¶ï¼Œæ˜¾è‘—æé«˜äº†å¯¹è¯å†å²çš„ç›¸å…³æ€§è¯†åˆ«.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šæé«˜äº†æœ€å¤š14.66%ï¼Œå¹¶åœ¨åŠ¨æ€ç®¡ç†è®°å¿†æ–¹é¢å±•ç°äº†ä¼˜åŠ¿.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-05-30</td>
        <td style="width: 55%;"><strong>M+ï¼šExtending MemoryLLM with scalable Long-Term Memory</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Copy_Suppression_Head-blue" alt="Copy Suppression Head Badge"></td>
        <td style="width: 15%;"><a href="https://arxiv.org/abs/2310.04625"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a> <a href="https://copy-suppression.streamlit.app/"><img src="https://arxiv.org/pdf/2502.00592" alt="Demo Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ M+æ˜¯ä¸€ç§è®°å¿†å¢å¼ºæ¨¡å‹ï¼Œæ—¨åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æœŸä¿¡æ¯ä¿ç•™æ–¹é¢çš„èƒ½åŠ›.<br>
          â€¢ M+åŸºäºMemoryLLMï¼Œé€šè¿‡æ•´åˆé•¿æœŸè®°å¿†æœºåˆ¶å’Œå…±åŒè®­ç»ƒçš„æ£€ç´¢å™¨ï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¤„ç†è¶…è¿‡20,000 tokensçŸ¥è¯†çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒç›¸ä¼¼çš„GPUå†…å­˜å¼€é”€.<br>
          â€¢ M+åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†MemoryLLMåŠå…¶ä»–å¼ºåŸºçº¿æ¨¡å‹ï¼Œå±•ç°å‡ºé«˜æ•ˆçš„ä¿¡æ¯å‹ç¼©å’Œç«¯åˆ°ç«¯è®­ç»ƒèƒ½åŠ›ï¼Œæ¥è¿‘äººç±»è®°å¿†çš„æœºåˆ¶.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-02-25</td>
        <td style="width: 55%;"><strong>Towards effective evaluation and comparisons for LLM unlearning methods</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Truthfulness_Head-blue" alt="Truthfulness Head Badge"></td>
        <td style="width: 15%;"><a href="https://openreview.net/forum?id=aLLuYpn83y"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a> <a href="https://arxiv.org/pdf/2406.09179"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ è®ºæ–‡æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„æœºå™¨é—å¿˜åŠå…¶è¯„ä¼°çš„é‡è¦æ€§ï¼Œå°¤å…¶å…³æ³¨å¦‚ä½•æ¶ˆé™¤ä¸å¿…è¦çš„æ•°æ®è®°å¿†.<br>
          â€¢ å¼•å…¥â€œæ§åˆ¶åå­¦ä¹ â€ï¼ˆUWCï¼‰æ–¹æ³•ï¼Œä»¥æ ¡å‡†æ¨¡å‹æ€§èƒ½ï¼Œå¢å¼ºä¸åŒé—å¿˜æ–¹æ³•çš„è¯„ä¼°èƒ½åŠ›.<br>
          â€¢ ç ”ç©¶å¼ºè°ƒé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡çš„é‡è¦æ€§ï¼Œæ¨èä½¿ç”¨â€œæå–å¼ºåº¦â€ï¼ˆESï¼‰ä½œä¸ºä¸»è¦è¯„ä¼°å·¥å…·ï¼Œä»è€Œä¿è¯è¯„ä¼°çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-01-19</td>
        <td style="width: 55%;"><strong>Alternate Preference Optimization for Unlearning Factual Knowledge in Large Language Models</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
        <td style="width: 15%;"><a href="https://aclanthology.org/2025.coling-main.252.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a><a href="https://github.com/albietz/transformer-birth"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æå‡ºæ–¹æ³•â€œAlternate Preference Optimizationâ€ï¼ˆAltPOï¼‰ï¼Œæ—¨åœ¨æœ‰æ•ˆè§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨â€œæœºå™¨é—å¿˜â€è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜.<br>
          â€¢ AltPOæ–¹æ³•é€šè¿‡ç»“åˆé—å¿˜é›†çš„è´Ÿåé¦ˆå’Œæ¥è‡ªåŒé¢†åŸŸçš„æ­£åé¦ˆï¼Œç”Ÿæˆå¤šä¸ªå¯æ›¿ä»£ç­”æ¡ˆï¼Œä»è€Œæé«˜é—å¿˜èƒ½åŠ›ï¼Œä¿æŒæ¨¡å‹çš„æ•´ä½“æ€§èƒ½.<br>
          â€¢ å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAltPOåœ¨é—å¿˜è´¨é‡å’Œæ¨¡å‹å®ç”¨æ€§æ–¹é¢çš„è¡¨ç°è¶…è¶Šäº†ç°æœ‰æ–¹æ³•.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-12-17</td>
      <td style="width: 55%;"><strong>On the Structural Memory of LLM Agents</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2412.15266"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ è®ºæ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­è®°å¿†æ¨¡å—çš„ç»“æ„ä¸æ£€ç´¢æ–¹æ³•å¦‚ä½•å½±å“å…¶æ€§èƒ½ï¼Œé‡ç‚¹åˆ†æäº†ä¸åŒçš„è®°å¿†ç»“æ„åŠå…¶åœ¨ä¿¡æ¯æå–å’Œç”Ÿæˆä¸­çš„åº”ç”¨.<br>
          â€¢ ç ”ç©¶å‘ç°ï¼Œæ··åˆè®°å¿†ç»“æ„åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶åœ¨å™ªå£°ç¯å¢ƒä¸‹æ›´å…·éŸ§æ€§.<br>
          â€¢ é€šè¿‡å¯¹è¶…å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æï¼Œç ”ç©¶è¯†åˆ«å‡ºåœ¨ä¸åŒä»»åŠ¡èƒŒæ™¯ä¸‹é€‚åˆçš„è®°å¿†æ£€ç´¢ç­–ç•¥.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2024-10-10</td>
        <td style="width: 55%;"><strong>Assessing episodic memory in LLMs with sequence order recall tasks</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Correct_Letter_Head-blue" alt="Correct Letter Head Badge"> <img src="https://img.shields.io/badge/Content_Gatherer_Head-blue" alt="Content Gatherer Head Badge"> <img src="https://img.shields.io/badge/Amplification_Head-blue" alt="Amplification Head Badge"> <img src="https://img.shields.io/badge/Constant_Head-blue" alt="Constant Head Badge"> <img src="https://img.shields.io/badge/Single_Letter_Head-blue" alt="Single Letter Head Badge"></td>
        <td style="width: 15%;"><a href="https://arxiv.org/pdf/2410.08133"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æœ¬ç ”ç©¶ä»‹ç»äº†åºåˆ—é¡ºåºå›å¿†ä»»åŠ¡(SORT),æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æƒ…èŠ‚è®°å¿†èƒ½åŠ›.<br>
          â€¢ è¯¥ä»»åŠ¡å¼ºè°ƒäº†æƒ…èŠ‚è®°å¿†çš„é‡è¦æ€§ï¼Œå³å°†è®°å¿†ä¸ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆå¦‚æ—¶é—´å’Œåœ°ç‚¹ï¼‰ç›¸ç»“åˆï¼Œå°¤å…¶æ˜¯åœ¨æ—¥å¸¸è®¤çŸ¥ä»»åŠ¡ä¸­çš„åº”ç”¨ä¸­.<br>
          â€¢ åˆæ­¥ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨æä¾›ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹èƒ½å¤Ÿè¡¨ç°å‡ºè¾ƒå¥½çš„è®°å¿†èƒ½åŠ›ï¼Œä½†åœ¨ä»…ä¾èµ–è®­ç»ƒæ•°æ®æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—é™ä½.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2024-08-11</td>
        <td style="width: 55%;"><strong>Towards Safer Large Language Models through Machine Unlearning</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"> <img src="https://img.shields.io/badge/S--Inhibition_Head-blue" alt="S-Inhibition Head Badge"> <img src="https://img.shields.io/badge/Name_Mover_Head-blue" alt="Name Mover Head Badge"> <img src="https://img.shields.io/badge/Previous_Token_Head-blue" alt="Previous Token Head Badge"> <img src="https://img.shields.io/badge/Duplicate_Token_Head-blue" alt="Duplicate Token Head Badge"> <img src="https://img.shields.io/badge/Negative_Name_Mover_Head-blue" alt="Negative Name Mover Head Badge"> <img src="https://img.shields.io/badge/Backup_Name_Mover_Head-blue" alt="Backup Name Mover Head Badge"></td>
        <td style="width: 15%;"><a href="https://aclanthology.org/2024.findings-acl.107.pdf"><img src="https://img.shields.io/badge/ICLR-Paper-%23D2691E" alt="Paper Badge"></a> <a href="https://github.com/redwoodresearch/Easy-Transformer"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æœ¬æ–‡ä»‹ç»äº†é€‰æ‹©æ€§çŸ¥è¯†å¦å®šé—å¿˜æ¡†æ¶ï¼ˆSKUï¼‰ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å®‰å…¨æ€§.<br>
          â€¢ SKUæ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºæœ‰å®³çŸ¥è¯†è·å–ï¼›ç¬¬äºŒé˜¶æ®µä¸ºçŸ¥è¯†å¦å®šï¼Œé‡ç‚¹å»é™¤ä¸è‰¯çŸ¥è¯†è€Œä¸æŸå®³æ­£å¸¸æç¤ºä¸‹æ¨¡å‹çš„æ•ˆç”¨.<br>
          â€¢ SKUæˆåŠŸåœ°åœ¨å‡å°‘æœ‰å®³è¾“å‡ºçš„åŒæ—¶ï¼Œä¿æŒäº†æ¨¡å‹çš„å“åº”è´¨é‡ï¼Œå¹¶åœ¨å¤šä¸ªLLMæ¶æ„ï¼ˆå¦‚OPTã€LLAMA2ï¼‰ä¸Šå±•ç¤ºäº†è‰¯å¥½çš„å»å­¦ä¹ ä¸æ•ˆç”¨æ€§èƒ½å¹³è¡¡.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-08-06</td>
      <td style="width: 55%;"><strong>RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2404.06654"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ RULERæ˜¯ç”¨äºå…¨é¢è¯„ä¼°é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­çš„æ€§èƒ½.<br>
          â€¢ RULERæ‰©å±•äº†ä¼ ç»Ÿçš„ï¼ˆNIAHï¼‰æµ‹è¯•ï¼ŒåŠ å…¥äº†å¤šè·³è¿½è¸ªã€èšåˆç­‰ä»»åŠ¡ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¡¡é‡æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ä¸‹çš„ç†è§£èƒ½åŠ›.<br>
          â€¢ RULERåœ¨å¤šè·³æ¨ç†å’Œä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰².
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-07-22</td>
      <td style="width: 55%;"><strong>A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2402.09727"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ReadAgentæ˜¯ä¸€ä¸ªæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶æ€§èƒ½çš„é˜…è¯»ç†è§£ç³»ç»Ÿ.<br>
          â€¢ é€šè¿‡æƒ…èŠ‚åˆ†é¡µã€è®°å¿†æ‘˜è¦å’Œäº’åŠ¨æŸ¥æ‰¾ä¸‰ç§æ­¥éª¤ï¼ŒReadAgentæ˜¾è‘—å¢åŠ äº†æœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæœ€å¤šå¯è¾¾20å€.<br>
          â€¢ ReadAgentåœ¨é•¿æ–‡æ¡£é˜…è¯»ç†è§£ä»»åŠ¡ï¼ˆå¦‚QuALITYã€NarrativeQAå’ŒQMSumï¼‰ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-06-30</td>
      <td style="width: 55%;"><strong>Towards Efficient and Effective Unlearning of Large Language Models for Recommendation</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2403.03536"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ä»‹ç»äº†ä¸€ç§æ¨èæ•°æ®é—å¿˜æ–¹æ³•E2URecï¼Œä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨èç³»ç»Ÿï¼ˆLLMRecï¼‰è®¾è®¡.<br>
          â€¢ E2URecé€šè¿‡ä»…æ›´æ–°ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å‚æ•°ï¼Œæ˜¾è‘—æé«˜äº†é—å¿˜æ•ˆç‡ï¼Œå¹¶ä¿æŒæ¨èæ€§èƒ½.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒE2URecåœ¨å®é™…æ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-05-26</td>
      <td style="width: 55%;"><strong>MemoryLLM:Towards self-Update Large Language Models</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2402.04624"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ MEMORYLLMæ˜¯ä¸€ç§è‡ªæˆ‘æ›´æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨æœ‰æ•ˆæ•´åˆæ–°çŸ¥è¯†å¹¶ä¿æŒé•¿æœŸä¿¡æ¯ä¿ç•™èƒ½åŠ›.<br>
          â€¢ é€šè¿‡åœ¨transformçš„æ½œåœ¨ç©ºé—´ä¸­åµŒå…¥å›ºå®šå¤§å°çš„è®°å¿†æ± ï¼ŒMEMORYLLMå®ç°äº†æ¨¡å‹è‡ªæˆ‘æ›´æ–°ä¸çŸ¥è¯†ä¿ç•™çš„æœ‰æœºç»“åˆ.<br>
          â€¢ æ¨¡å‹çš„è®¾è®¡ç‰¹ç‚¹åŒ…æ‹¬ï¼šåŒ…å«å‹ç¼©çŸ¥è¯†çš„è®°å¿†ä»¤ç‰Œã€æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°æœºåˆ¶ä»¥åŠé’ˆå¯¹çŸ¥è¯†æ•´åˆã€ä¿ç•™èƒ½åŠ›å’Œé²æ£’æ€§çš„è¯¦ç»†è¯„ä¼°.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-04-13</td>
      <td style="width: 55%;"><strong>LLM In-Context Recall is Prompt Dependen</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2404.08865"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¿¡æ¯å›å¿†èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ï¼Œå°¤å…¶å¼ºè°ƒå…¶å¯¹æç¤ºå†…å®¹å’Œæ ¼å¼çš„ä¾èµ–æ€§.<br>
          â€¢ é€šè¿‡é‡‡ç”¨(NIAH)æµ‹è¯•æ–¹æ³•ï¼Œå‘ç°æ¨¡å‹çš„å¬å›èƒ½åŠ›å—è®­ç»ƒæ•°æ®åå·®ã€æç¤ºå†…å®¹å’Œæ ¼å¼å½±å“æ˜¾è‘—.<br>
          â€¢ é€šè¿‡ä¼˜åŒ–æ¨¡å‹æ¶æ„ã€è°ƒæ•´è®­ç»ƒç­–ç•¥åŠå®æ–½å¾®è°ƒï¼Œå‡èƒ½æœ‰æ•ˆæå‡å¬å›æ€§èƒ½.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-03-24</td>
      <td style="width: 55%;"><strong>MemoryBank: Enhancing Large Language Models with Long-Term Memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29946"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ â€œMemoryBankâ€ï¼Œä¸€ç§ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®¾è®¡çš„é•¿æ—¶è®°å¿†æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³LLMsåœ¨æŒç»­äº’åŠ¨ä¸­è®°å¿†ä¸è¶³çš„é—®é¢˜.<br>
          â€¢ MemoryBanké€šè¿‡å…è®¸æ¨¡å‹æœ‰æ•ˆå¬å›ã€æ›´æ–°å’Œé€‚åº”ç”¨æˆ·è®°å¿†ï¼Œä»¥æå‡ä¸Šä¸‹æ–‡ç†è§£å’Œç”¨æˆ·ä½“éªŒ.<br>
          â€¢ é€šè¿‡å®éªŒå’Œåˆ†æï¼ŒMemoryBankåœ¨æé«˜æƒ…æ„Ÿæ”¯æŒå’Œä¸ªæ€§åŒ–äº’åŠ¨æ–¹é¢æ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-02-16</td>
      <td style="width: 55%;"><strong>Large Language Model Unlearning</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2310.10683"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å®æ–½â€œé—å¿˜â€æˆ–â€œåå­¦ä¹ â€çš„æ–¹æ³•ï¼Œä»¥å»é™¤ä¸å¸Œæœ›å‡ºç°çš„ï¼ˆè¯¯ï¼‰è¡Œä¸º.<br>
          â€¢ é€šè¿‡åº”ç”¨æ¢¯åº¦ä¸Šå‡ï¼ˆGAï¼‰ç­–ç•¥å’Œå¼•å…¥éšæœºè¾“å‡ºæŸå¤±ï¼Œç ”ç©¶å±•ç¤ºäº†åå­¦ä¹ èƒ½åœæ­¢æ¨¡å‹ç”Ÿæˆæœ‰å®³ç­”æ¡ˆçš„èƒ½åŠ›.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒGAå’ŒGA+Mismatchæ–¹æ³•åœ¨é™ä½å†…å®¹æ³„æ¼ç‡æ–¹é¢è¡¨ç°ä¼˜å¼‚.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2024-02-06</td>
      <td style="width: 55%;"><strong>Compressed context memory for online language model interaction</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2312.03414"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æå‡ºä¸€ç§å‹ç¼©ä¸Šä¸‹æ–‡è®°å¿†æ–¹æ³•ï¼Œç”¨äºæé«˜åœ¨çº¿è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ‰©å±•ä¸Šä¸‹æ–‡æ—¶çš„å†…å­˜æ•ˆç‡å’Œè®¡ç®—æ€§èƒ½.<br>
          â€¢ é€šè¿‡é‡‡ç”¨æ¡ä»¶LoRAé›†æˆå’Œå¹¶è¡Œè®¡ç®—ï¼Œæ˜¾è‘—å‡å°‘å†…å­˜éœ€æ±‚ï¼Œå®ç°äº†å¯¹æ— é™ä¸Šä¸‹æ–‡é•¿åº¦çš„å¤„ç†èƒ½åŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿæ»‘åŠ¨çª—å£ç­–ç•¥.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä»»åŠ¡å­¦ä¹ å’Œå¯¹è¯ç”Ÿæˆç­‰åº”ç”¨åœºæ™¯ä¸­ï¼Œè¯¥æ–¹æ³•çš„å†…å­˜éœ€æ±‚é™ä½äº†äº”å€ï¼ŒåŒæ—¶æœ‰æ•ˆä¿æŒäº†ç”Ÿæˆæ€§èƒ½å’Œå‡†ç¡®æ€§.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2023-12-10</td>
      <td style="width: 55%;"><strong>Unlearn What You Want to Forget: Efficient Unlearning for LLMs</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/anthology-files/pdf/emnlp/2023.emnlp-main.738.pdf"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ â€œé—å¿˜â€æ¡†æ¶ï¼ˆEfficient Unlearning, EULï¼‰ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†ç”¨æˆ·éšç§æ•°æ®æ—¶çš„æŒ‘æˆ˜.<br>
          â€¢ éšç€LLMsçš„å¹¿æ³›åº”ç”¨ï¼Œæ¨¡å‹åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šè®°ä½æ•æ„Ÿä¿¡æ¯ï¼Œä»è€Œå¼•å‘éšç§é—®é¢˜.<br>
          â€¢ EULå…è®¸åœ¨ä¸å®Œå…¨é‡è®­æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°ä»LLMsä¸­åˆ é™¤ç‰¹å®šçš„æ•æ„Ÿæ•°æ®ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„é¢„æµ‹æ€§èƒ½.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2023-11-15</td>
      <td style="width: 55%;"><strong>Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2311.08719"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ä¸€ç§æ–°çš„è®°å¿†æœºåˆ¶â€œThink-in-Memoryâ€ï¼ˆTiMï¼‰ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æœŸäººæœºäº¤äº’ä¸­çš„è¡¨ç°.<br>
          â€¢ TiMå¼•å…¥äº†åŸºäºå±€éƒ¨æ•æ„Ÿå“ˆå¸Œçš„é«˜æ•ˆæ£€ç´¢æœºåˆ¶ï¼Œä»¥æ”¯æŒé•¿æœŸäº¤äº’ä¸­çš„è®°å¿†å­˜å‚¨å’Œç®¡ç†.<br>
          â€¢ å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTiMåœ¨å¤šè½®å¯¹è¯ä¸­æ˜¾è‘—æ”¹å–„äº†LLMsçš„å“åº”å‡†ç¡®æ€§å’Œè¿è´¯æ€§.
        </td>
    </tr>
     <tr>
      <td rowspan="2" style="width: 15%;">2023-09-22</td>
      <td style="width: 55%;"><strong>Augmenting Language Models with Long-Term Memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://papers.nips.cc/paper_files/paper/2023/file/ebd82705f44793b6f9ade5a669d0f0bf-Paper-Conference.pdf"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ä»‹ç»äº†ä¸€ç§æ–°çš„æ¡†æ¶LONGMEMï¼Œæ—¨åœ¨å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ–‡æœ¬å¤„ç†ä¸­çš„èƒ½åŠ›.<br>
          â€¢ LONGMEMé€šè¿‡è®¾è®¡ä¸€ä¸ªè§£è€¦çš„ç½‘ç»œæ¶æ„ï¼Œç»“åˆå†»ç»“çš„LLMè®°å¿†ç¼–ç å™¨ä¸è‡ªé€‚åº”çš„æ®‹å·®ä¾§ç½‘ç»œï¼Œæœ‰æ•ˆåœ°ç¼“å­˜å’Œæ›´æ–°é•¿æ—¶é—´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯.<br>
          â€¢ é€šè¿‡å¼•å…¥ç‰¹æ®Šçš„è®°å¿†å¢å¼ºå±‚ã€åŸºäºä»¤ç‰Œçš„è®°å¿†æ£€ç´¢æ¨¡å—å’Œè”åˆæ³¨æ„åŠ›æœºåˆ¶ï¼ŒLONGMEMæé«˜äº†æ¨¡å‹çš„è®°å¿†æ£€ç´¢èƒ½åŠ›å’Œä¸Šä¸‹æ–‡åˆ©ç”¨æ•ˆæœï¼ŒéªŒè¯äº†å…¶åœ¨å¤šç§ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§.
        </td>
    </tr>

  </table>

</details>

<details>
  <summary><strong>Datasets & Benchmark</strong></summary>

  <table style="width: 100%;">
    <tr>
      <td><strong>Date</strong></td>
      <td><strong>Paper & Summary</strong></td>
      <td><strong>Tags</strong></td>
      <td><strong>Links</strong></td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-11-04</td>
      <td style="width: 55%;"><strong>Toward Multi-Session Personalized Conversation: A Large-Scale Dataset and Hierarchical Tree Framework for Implicit Reasoning</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Previous_Head-blue" alt="Previous Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2025.emnlp-main.580.pdf"><img src="https://img.shields.io/badge/Blog-Post-black" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æå‡ºäº†IMPLEXCONVæ•°æ®é›†å’ŒTACITREEæ¡†æ¶ï¼Œç”¨äºç ”ç©¶ä¸ªæ€§åŒ–å¯¹è¯ä¸­çš„éšæ€§æ¨ç†.<br>
          â€¢ IMPLEXCONVåŒ…å«2500ä¸ªç¤ºä¾‹ï¼Œä¸“æ³¨äºéšæ€§æ¨ç†åœºæ™¯ï¼Œæ•æ‰å¯¹è¯ä¸­å¾®å¦™çš„å¥æ³•å’Œè¯­ä¹‰å…³ç³».<br>
          â€¢ TACITREEé€šè¿‡å±‚æ¬¡åŒ–ç»„ç»‡å¯¹è¯å†å²ï¼Œæé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é•¿å¯¹è¯ä¸­çš„éšæ€§ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-10-27</td>
      <td style="width: 55%;"><strong>Know Me, Respond to Me, benchmarking LLMs for Dynamic User profiling and personalized response at scale</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Detection_Head-blue" alt="Detection Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2504.14225"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ä»‹ç»PERSONAMEMåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠ¨æ€ç”¨æˆ·ç”»åƒå’Œä¸ªæ€§åŒ–å“åº”ä¸­çš„è¡¨ç°.<br>
          â€¢ å°½ç®¡ç°æœ‰æ¨¡å‹åœ¨å›å¿†ç”¨æˆ·åå¥½æ–¹é¢å–å¾—äº†ä¸€å®šæˆåŠŸï¼Œä½†åœ¨å¤„ç†æ–°åœºæ™¯æ—¶ä»å­˜åœ¨æ˜¾è‘—æ€§èƒ½ä¸è¶³.<br>
          â€¢ æ–‡æœ¬è¯¦ç»†æè¿°äº†åŸºå‡†çš„ç»“æ„ã€ç”Ÿæˆç”¨æˆ·å¯¹è¯çš„è¿‡ç¨‹ã€è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ä»¥åŠä¸€äº›ç›¸å…³ç ”ç©¶ï¼Œå¼ºè°ƒäº†ä¸ªæ€§åŒ–å¯¹è¯ç”Ÿæˆåœ¨æå‡ç”¨æˆ·ä½“éªŒä¸­çš„é‡è¦æ€§.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2023-09-26</td>
      <td style="width: 55%;"><strong>Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Direct_effect_Head-blue" alt="Direct Effect Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2507.05257"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ MemoryAgentBenchåŸºå‡†ç”¨äºè¯„ä¼°å…·æœ‰è®°å¿†æœºåˆ¶çš„è¯­è¨€æ¨¡å‹ï¼ˆMemory Agentsï¼‰çš„å››å¤§æ ¸å¿ƒèƒ½åŠ›ï¼šå‡†ç¡®æ£€ç´¢ã€æµ‹è¯•æ—¶å­¦ä¹ ã€é•¿èŒƒå›´ç†è§£å’Œå†²çªè§£å†³.<br>
          â€¢ é€šè¿‡æ•´åˆç°æœ‰æ•°æ®é›†å’Œæ–°æ„å»ºçš„æ•°æ®ï¼ŒMemoryAgentBenchæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°è¿™äº›èƒ½åŠ›.<br>
          â€¢ MemoryAgentBenchæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°è¿™äº›èƒ½åŠ›ï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•åœ¨è®°å¿†æ›´æ–°å’Œé•¿å¯¹è¯å¤„ç†ä¸­å­˜åœ¨çš„ä¸è¶³ä¹‹å¤„.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-07-27</td>
        <td style="width: 55%;"><strong>PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Copy_Suppression_Head-blue" alt="Copy Suppression Head Badge"></td>
        <td style="width: 15%;"><a href="https://aclanthology.org/2025.findings-acl.49.pdf"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a> <a href="https://copy-suppression.streamlit.app/"><img src="https://img.shields.io/badge/Demo-View-purple?logo=internet-explorer" alt="Demo Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ "PersonaBench"æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIæ¨¡å‹åœ¨ç†è§£ä¸ªäººä¿¡æ¯æ–¹é¢çš„åŸºå‡†.<br>
          â€¢ è®ºæ–‡æŒ‡å‡ºä¸ªæ€§åŒ–åœ¨AIåŠ©æ‰‹ä¸­çš„é‡è¦æ€§ï¼Œå¹¶å¼ºè°ƒäº†ç¼ºä¹å…¬å¼€æ•°æ®é›†ä»¥è¯„ä¼°å¯¹æ­¤ç±»ä¿¡æ¯çš„ç†è§£èƒ½åŠ›è¿™ä¸€æŒ‘æˆ˜.<br>
          â€¢ è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¨¡å‹ä¸Šï¼Œç»“æœæ˜¾ç¤ºå½“å‰æ¨¡å‹å¯¹äºå¤„ç†ä¸ªäººé—®é¢˜çš„èƒ½åŠ›å°šæ˜¾ä¸è¶³.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-07-27</td>
        <td style="width: 55%;"><strong>MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Truthfulness_Head-blue" alt="Truthfulness Head Badge"></td>
        <td style="width: 15%;"><a href="https://aclanthology.org/2025.findings-acl.989.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a> <a href="https://github.com/likenneth/honest_llama"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ MemBenchæ—¨åœ¨å…¨é¢è¯„ä¼°åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„è®°å¿†èƒ½åŠ›.<br>
          â€¢ é€šè¿‡å»ºç«‹æ¶µç›–äº‹å®è®°å¿†å’Œåæ€è®°å¿†çš„æ•°æ®é›†ï¼Œç ”ç©¶è§£å†³äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§.<br>
          â€¢ æ–‡æœ¬è¯¦ç»†æè¿°äº†è®°å¿†æœºåˆ¶çš„æ„å»ºï¼ŒåŒ…æ‹¬ç”¨æˆ·å…³ç³»å›¾å’Œå¤šå±‚è®°å¿†çš„è®¾è®¡ï¼Œå¼ºè°ƒè¯„ä¼°å‡†ç¡®æ€§ã€æ•ˆç‡ã€å®¹é‡ç­‰æŒ‡æ ‡çš„é‡è¦æ€§.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-07-27</td>
        <td style="width: 55%;"><strong>Evaluating the Long-term memory of large language models</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
        <td style="width: 15%;"><a href="https://aclanthology.org/2025.findings-acl.1014.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a> <a href="https://github.com/albietz/transformer-birth"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æœ¬æ–‡ç ”ç©¶äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æœŸä»»åŠ¡ä¸­çš„è®°å¿†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„åº”ç”¨è¡¨ç°.<br>
          â€¢ é€šè¿‡æ„å»ºâ€œé•¿æœŸæ—¶é—´é¡ºåºå¯¹è¯â€ï¼ˆLOCCOï¼‰æ•°æ®é›†ï¼Œé‡åŒ–è¯„ä¼°äº†LLMsçš„é•¿æœŸè®°å¿†èƒ½åŠ›.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šä¿ç•™å†å²å¯¹è¯ä¿¡æ¯ï¼Œä½†éšç€æ—¶é—´æ¨ç§»ï¼Œå…¶è®°å¿†èƒ½åŠ›é€æ¸è¡°å‡.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-07-27</td>
      <td style="width: 55%;"><strong>Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2025.acl-long.1025.pdf"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ ä»‹ç»äº†ä¸€ç§ç”¨æˆ·æ¨¡æ‹Ÿæ¡†æ¶â€œéšå¼ç”¨æˆ·æ¡£æ¡ˆç”¨æˆ·æ¨¡æ‹Ÿå™¨â€ï¼ˆUSPï¼‰ï¼Œæ—¨åœ¨é€šè¿‡æ¨æ–­ç”¨æˆ·çš„éšå¼ç‰¹å¾æ¥å¢å¼ºå¯¹è¯ç³»ç»Ÿä¸äººç±»ç”¨æˆ·çš„äº¤äº’.<br>
          â€¢ USPé€šè¿‡æå–ç”¨æˆ·å¯¹è¯ä¸­çš„éšå¼ç‰¹å¾ï¼Œå¹¶ç»“åˆæ¡ä»¶ç›‘ç£å¾®è°ƒå’Œå¾ªç¯ä¸€è‡´æ€§çš„å¼ºåŒ–å­¦ä¹ ï¼Œä¼˜åŒ–äº†å¯¹è¯çš„çœŸå®æ€§å’Œä¸€è‡´æ€§.<br>
          â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒUSPåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šï¼Œå°¤å…¶æ˜¯ä¸å…¶ä»–å¯¹è¯ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚GPT-4oå’ŒPlatoLMï¼‰çš„æ¯”è¾ƒä¸­ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—ä¼˜åŠ¿.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-06-15</td>
        <td style="width: 55%;"><strong>PersonaFeedback: A Large-scale Human-annotated Benchmark For Personalization</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Correct_Letter_Head-blue" alt="Correct Letter Head Badge"> <img src="https://img.shields.io/badge/Content_Gatherer_Head-blue" alt="Content Gatherer Head Badge"> <img src="https://img.shields.io/badge/Amplification_Head-blue" alt="Amplification Head Badge"> <img src="https://img.shields.io/badge/Constant_Head-blue" alt="Constant Head Badge"> <img src="https://img.shields.io/badge/Single_Letter_Head-blue" alt="Single Letter Head Badge"></td>
        <td style="width: 15%;"><a href="https://arxiv.org/pdf/2506.12915"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ æå‡ºåŸºå‡†PersonaFeedbackï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸ªæ€§åŒ–å“åº”æ–¹é¢çš„èƒ½åŠ›.<br>
          â€¢ ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡LLMsåœ¨ç”Ÿæˆä¸ªæ€§åŒ–å†…å®¹æ–¹é¢æœ‰è¿›å±•ï¼Œä½†åœ¨å¤æ‚æƒ…å¢ƒä¸­ä¾ç„¶å­˜åœ¨å±€é™æ€§.<br>
          â€¢ é€šè¿‡ä½¿ç”¨åŠ¨æ€ç”¨æˆ·ç‰¹å¾æ¨æ–­ã€ä¸ªæ€§åŒ–æ¡£æ¡ˆå’Œå¥–åŠ±æ¨¡å‹ï¼Œç ”ç©¶è€…ä»¬åŠªåŠ›æå‡ä¸ªæ€§åŒ–é—®ç­”çš„æ•ˆæœ.
        </td>
    </tr>
    <tr>
        <td rowspan="2" style="width: 15%;">2025-06-09</td>
        <td style="width: 55%;"><strong>Minerva: A Programmable memory test benchmark for language models</strong></td>
        <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"> <img src="https://img.shields.io/badge/S--Inhibition_Head-blue" alt="S-Inhibition Head Badge"> <img src="https://img.shields.io/badge/Name_Mover_Head-blue" alt="Name Mover Head Badge"> <img src="https://img.shields.io/badge/Previous_Token_Head-blue" alt="Previous Token Head Badge"> <img src="https://img.shields.io/badge/Duplicate_Token_Head-blue" alt="Duplicate Token Head Badge"> <img src="https://img.shields.io/badge/Negative_Name_Mover_Head-blue" alt="Negative Name Mover Head Badge"> <img src="https://img.shields.io/badge/Backup_Name_Mover_Head-blue" alt="Backup Name Mover Head Badge"></td>
        <td style="width: 15%;"><a href="https://arxiv.org/pdf/2502.03358"><img src="https://img.shields.io/badge/ICLR-Paper-%23D2691E" alt="Paper Badge"></a> <a href="https://github.com/redwoodresearch/Easy-Transformer"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a></td>
    </tr>
    <tr>
        <td colspan="3">
          â€¢ Minervaæ˜¯ä¸€ä¸ªå¯ç¼–ç¨‹è®°å¿†æµ‹è¯•åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸åŒè®°å¿†ä»»åŠ¡ä¸­çš„èƒ½åŠ›.<br>
          â€¢ é€šè¿‡å®šé‡è¯„ä¼°æ¨¡å‹åœ¨è®°å¿†ä½¿ç”¨æ–¹é¢çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯ä¿¡æ¯æ£€ç´¢ã€æ¨ç†å’ŒçŠ¶æ€è·Ÿè¸ªç­‰ä»»åŠ¡.<br>
          â€¢ å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡éƒ¨åˆ†æ¨¡å‹åœ¨ç®€å•ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ä¸­å­˜åœ¨æ˜æ˜¾å·®è·.
        </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2022-03-04</td>
      <td style="width: 55%;"><strong>LongMemEval: Benchmarking chat assistants on long-term interactive memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2410.10813"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ è®ºæ–‡ä»‹ç»äº†LONGMEMEVALï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°èŠå¤©åŠ©æ‰‹é•¿æœŸè®°å¿†èƒ½åŠ›çš„ç»¼åˆåŸºå‡†.<br>
        â€¢ è¯¥åŸºå‡†è¯„ä¼°äº”ç§æ ¸å¿ƒè®°å¿†èƒ½åŠ›ï¼Œå¯åæ˜ ç°æœ‰ç³»ç»Ÿå­˜åœ¨çš„æŒ‘æˆ˜.<br>
        â€¢ LONGMEMEVALé‡‡ç”¨ä¸€ç§ç»Ÿä¸€çš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼ˆç´¢å¼•ã€æ£€ç´¢ã€é˜…è¯»ï¼‰ï¼Œå¹¶æå‡ºå¤šé¡¹è®¾è®¡ä¼˜åŒ–ç­–ç•¥ä»¥æé«˜è®°å¿†å¬å›ç‡å’Œé—®ç­”å‡†ç¡®æ€§.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-02-25</td>
      <td style="width: 55%;"><strong>Towards Effective Evaluations and Comparisons for LLM Unlearning Methods</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2406.09179"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„æœºå™¨é—å¿˜åŠå…¶è¯„ä¼°çš„é‡è¦æ€§ï¼Œå°¤å…¶å…³æ³¨å¦‚ä½•æ¶ˆé™¤ä¸å¿…è¦çš„æ•°æ®è®°å¿†.<br>
        â€¢ ç ”ç©¶ä¸»è¦é¢å¯¹ä¸¤ä¸ªæŒ‘æˆ˜ï¼šä¸€æ˜¯è¯„ä¼°æŒ‡æ ‡çš„ç¨³å¥æ€§ï¼ŒäºŒæ˜¯æ¶ˆé™¤ç›®æ ‡çŸ¥è¯†ä¸ä¿ç•™å…¶ä»–çŸ¥è¯†ä¹‹é—´çš„æƒè¡¡.<br>
        â€¢ ç ”ç©¶æ¨èä½¿ç”¨â€œæå–å¼ºåº¦â€ï¼ˆESï¼‰ä½œä¸ºä¸»è¦è¯„ä¼°å·¥å…·ï¼Œä»è€Œä¿è¯è¯„ä¼°çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2022-02-13</td>
      <td style="width: 55%;"><strong>DO LLMS RECOGNIZE YOUR PREFERENCES? EVAL-UATING PERSONALIZED PREFERENCE FOLLOWING IN LLMS</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2502.09597"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ PREFEVALåŸºå‡†æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿å¯¹è¯ä¸­æ¨æ–­ã€è®°å¿†å’Œéµå¾ªç”¨æˆ·åå¥½çš„èƒ½åŠ›.<br>
        â€¢ è¯¥åŸºå‡†åŒ…å«3000ä¸ªç”¨æˆ·åå¥½å’ŒæŸ¥è¯¢å¯¹ï¼Œè¦†ç›–20ä¸ªä¸»é¢˜ï¼Œæ­ç¤ºäº†å½“å‰LLMsåœ¨éµå¾ªç”¨æˆ·åå¥½æ–¹é¢æ˜¾è‘—çš„æŒ‘æˆ˜.<br>
        â€¢ ç ”ç©¶è¡¨æ˜ï¼Œæ˜¾å¼åå¥½ç›¸è¾ƒäºéšå¼åå¥½æ›´æ˜“äºæ¨¡å‹æ¨æ–­ï¼Œè€Œä¸åŒä»»åŠ¡ç±»å‹å’Œåå¥½è¡¨è¾¾æ–¹å¼å¯¹æ¨¡å‹æ•ˆæœæœ‰æ˜¾è‘—å½±å“.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-01-23</td>
      <td style="width: 55%;"><strong>LongGenBench: Benchmarking long-form generation in long context LLMs</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2409.02076"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ LongGenBenchåŸºå‡†æµ‹è¯•æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆé«˜è´¨é‡é•¿æ–‡æœ¬ä¸­çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éµå¾ªå¤æ‚æŒ‡ä»¤æ–¹é¢.<br>
        â€¢ ä¸ç°æœ‰åŸºå‡†ä¸åŒï¼ŒLongGenBenchä¸“æ³¨äºé•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ï¼Œæ¶µç›–æ—¥è®°å†™ä½œã€èœå•è®¾è®¡ç­‰å¤šä¸ªä»»åŠ¡.<br>
        â€¢ å°½ç®¡LLMsåœ¨å…¶ä»–æµ‹è¯•ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨LongGenBenchçš„æµ‹è¯•ä¸­ï¼Œå®ƒä»¬é¢ä¸´æ˜¾è‘—çš„æŒ‘æˆ˜.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-11-12</td>
      <td style="width: 55%;"><strong>MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for  Large Language Models</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.emnlp-main.1124.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ MT-Eval åŸºå‡†æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°.<br>
        â€¢ å½“å‰çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨å•è½®å¯¹è¯ä¸Šï¼ŒMT-Eval é€šè¿‡æ„å»º1,170ä¸ªå¤šè½®æŸ¥è¯¢å¡«è¡¥äº†è¿™ä¸€ç©ºç™½.<br>
        â€¢ è¿™ä¸€åŸºå‡†å°†äº¤äº’æ¨¡å¼åˆ†ä¸ºå›å¿†ã€æ‰©å±•ã€ç²¾ç‚¼å’Œè·Ÿè¿›ï¼Œå±•ç¤ºäº†å¤§å¤šæ•°æ¨¡å‹åœ¨å¤šè½®è®¾ç½®ä¸­çš„è¡¨ç°æ™®éä½äºå•è½®è®¾ç½®.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-11-12</td>
      <td style="width: 55%;"><strong>LONGGENBENCH: Long-context Generation Benchmark</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.findings-emnlp.48.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ LongGenBenchæ˜¯æ–°æå‡ºçš„é•¿ä¸Šä¸‹æ–‡ç”ŸæˆåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°.<br>
        â€¢ è¿™ä¸€åŸºå‡†è¡¥å……äº†ç°æœ‰ä¸»è¦å…³æ³¨æ£€ç´¢æŠ€èƒ½çš„è¯„ä¼°æ–¹æ³•ï¼Œé‡ç‚¹æµ‹è¯•æ¨¡å‹å¯¹å¤šé—®é¢˜çš„è¿è´¯æ€§å’Œé€»è¾‘ä¸€è‡´æ€§.<br>
        â€¢ ç ”ç©¶è¡¨æ˜ï¼Œä¸åŒæ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„èƒ½åŠ›å·®å¼‚.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-08-16</td>
      <td style="width: 55%;"><strong>A personal long-term memory dataset for memory classification,Retrieval, and Synthesis in question Answering</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.sighan-1.18.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ ä¸€ä¸ªæ—¨åœ¨æå‡å¯¹è¯ç³»ç»Ÿä¸­é•¿æœŸè®°å¿†æ•´åˆçš„é—®é¢˜å›ç­”æ•°æ®é›†PerLTQA.<br>
        â€¢ PerLTQAç»“åˆäº†è¯­ä¹‰è®°å¿†å’Œæƒ…èŠ‚è®°å¿†ï¼ŒåŒ…å«8593ä¸ªé—®é¢˜ï¼Œæ¶‰åŠ30ä¸ªè§’è‰²ï¼Œç›®çš„æ˜¯æ”¹å–„è®°å¿†åˆ†ç±»ã€æ£€ç´¢å’Œåˆæˆ.<br>
        â€¢ å®éªŒè¡¨æ˜ï¼ŒåŸºäºBERTçš„æ¨¡å‹åœ¨è®°å¿†åˆ†ç±»ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–å¤§å‹è¯­è¨€æ¨¡å‹.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-08-11</td>
      <td style="width: 55%;"><strong>Evaluating Very Long-Term Conversational Memory of LLM Agents</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.acl-long.747.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ—¶é—´å¯¹è¯ä¸­çš„è®°å¿†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€å¯¹è¯åœºæ™¯ä¸­.<br>
        â€¢ é€šè¿‡å¼€å‘åä¸ºLOCOMOçš„æ•°æ®é›†ï¼Œç ”ç©¶è€…å»ºç«‹äº†ä¸€ä¸ªç»¼åˆè¯„ä¼°åŸºå‡†ï¼Œæ¶µç›–äº†é—®ç­”ã€äº‹ä»¶æ€»ç»“å’Œå¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆç­‰ä»»åŠ¡.<br>
        â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ä¸€äº›LLMsè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è®°å¿†å’Œæ¨ç†èƒ½åŠ›ä¸Šä»æ˜¾è‘—è½åäºäººç±»ï¼ŒåŒæ—¶æå‡ºäº†è¯„ä¼°æ¡†æ¶å’Œæœªæ¥æ”¹è¿›çš„æ–¹å‘.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-08-11</td>
      <td style="width: 55%;"><strong>Lamp: When large language models meet personalization</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.acl-long.399.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸ªæ€§åŒ–å“åº”ç”Ÿæˆä¸­çš„é‡è¦æ€§ï¼Œå¹¶å¼•å…¥äº†LaMPåŸºå‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè®­ç»ƒå’Œè¯„ä¼°ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆä¸åˆ†ç±»ä»»åŠ¡è€Œè®¾è®¡çš„æ–°æ¡†æ¶.<br>
        â€¢ LaMPåŒ…å«ä¸ƒä¸ªä¸ªæ€§åŒ–å­ä»»åŠ¡ï¼Œå¼ºè°ƒäº†é€šè¿‡ç”¨æˆ·ç‰¹å®šè¾“å…¥ï¼ˆå¦‚å†å²æ•°æ®ï¼‰å’Œæ£€ç´¢å¢å¼ºç­–ç•¥æå‡è¯­è¨€æ¨¡å‹çš„æ•ˆæœ.<br>
        â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ªæ€§åŒ–æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¾®è°ƒå’Œåˆé€‚çš„æ£€ç´¢ç­–ç•¥ä½¿ç”¨ä¸Šè¡¨ç°æœ€ä½³.
      </td>
    </tr>
  </table>

</details>

<details>
  <summary><strong>Memory Evaluation</strong></summary>

  <table style="width: 100%;">
    <tr>
      <td><strong>Date</strong></td>
      <td><strong>Paper & Summary</strong></td>
      <td><strong>Tags</strong></td>
      <td><strong>Links</strong></td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-10-10</td>
      <td style="width: 55%;"><strong>Human-inspired Episodic Memory for Infinite Context LLMs</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2407.09450"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ EM-LLMï¼ˆäº‹ä»¶è®°å¿†å¤§è¯­è¨€æ¨¡å‹ï¼‰æ˜¯ä¸€ç§æ–°å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å½“å‰æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶çš„å±€é™æ€§.<br>
        â€¢ EM-LLMå®ç°äº†æ— éœ€å¾®è°ƒçš„å‡ ä¹æ— é™ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›ï¼Œè¡¨ç°å‡ºåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºç°æœ‰æ¨¡å‹çš„æ˜¾è‘—æå‡.<br>
        â€¢ è¯¥æ¨¡å‹ç»“åˆäº†åŸºäºæƒŠè®¶çš„äº‹ä»¶åˆ†å‰²ã€å›¾è®ºè¾¹ç•Œç»†åŒ–ä»¥åŠåŒé˜¶æ®µçš„è®°å¿†æ£€ç´¢æœºåˆ¶ï¼Œæ˜¾è‘—æ”¹å–„äº†ä¿¡æ¯æ£€ç´¢å’Œé—®ç­”ä»»åŠ¡çš„æ€§èƒ½.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-07-27</td>
      <td style="width: 55%;"><strong>MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2025.acl-long.560.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ ä½æˆæœ¬é•¿æ–‡æœ¬ç†è§£åŸºå‡†MiniLongBenchæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ–‡æœ¬ç†è§£ï¼ˆLCUï¼‰èƒ½åŠ›è¯„ä¼°çš„æ•ˆç‡å’Œé™ä½æˆæœ¬.<br>
        â€¢ MiniLongBenché€šè¿‡æ•°æ®å‹ç¼©æŠ€æœ¯æ˜¾è‘—å‡å°‘äº†æµ‹è¯•æ ·æœ¬æ•°é‡ï¼Œä¿æŒäº†è¯„ä¼°ä¸€è‡´æ€§ï¼Œå¹¶ä¸ç°æœ‰çš„LongBenchåŸºå‡†çš„ç»“æœé«˜åº¦ç›¸å…³.<br>
        â€¢ MiniLongBenchåœ¨å¤šä¸ªä»»åŠ¡ç±»åˆ«ä¸‹çš„è¯„ä¼°æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ•ˆæœï¼Œå°½ç®¡ä»éœ€åœ¨æ€»ç»“å’Œåˆæˆä»»åŠ¡æ–¹é¢è¿›è¡Œæ”¹è¿›.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-05-28</td>
      <td style="width: 55%;"><strong>Self-Taught Agentic Long-Context Understanding</strong></td>
      <td style="width: 15%;">
        <img src="https://img.shields.io/badge/Local_Head-blue" alt="Local Head Badge">
        <img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge">
        <img src="https://img.shields.io/badge/Delimiter_Head-blue" alt="Delimiter Head Badge">
        <img src="https://img.shields.io/badge/Block_Head-blue" alt="Block Head Badge">
      </td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2502.15920"><img src="https://img.shields.io/badge/AAAI-Paper-%23D2691E" alt="Paper Badge"></a>
        <a href="https://github.com/iitmnlp/heads-hypothesis"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
      </td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ â€œAgentic Long-Context Understandingâ€ (AgenticLU) æ¡†æ¶æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ–‡æœ¬ç†è§£å’Œæ¨ç†æ–¹é¢çš„èƒ½åŠ›.<br>
        â€¢ AgenticLUé€šè¿‡å¼•å…¥â€œChain-of-Clarificationsâ€ (CoC) æœºåˆ¶ï¼Œä¼˜åŒ–äº†æ¨¡å‹çš„è‡ªæˆ‘æ¾„æ¸…è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨æ ‘çŠ¶æœç´¢è·¯å¾„ç”Ÿæˆæ¾„æ¸…é—®é¢˜ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†å¤šæ­¥æ¨ç†çš„å‡†ç¡®æ€§å’Œæ•ˆæœ.<br>
        â€¢ è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨é•¿æ–‡æœ¬é—®ç­”ä¸­è¶…è¶Šç°æœ‰æç¤ºæŠ€æœ¯ï¼ŒåŒæ—¶è®¡ç®—å¼€é”€å¾—åˆ°äº†æœ‰æ•ˆæ§åˆ¶.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-03-11</td>
      <td style="width: 55%;"><strong>SCBench: A Benchmark for Long Context Methods Based on KV-Cache</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Constituency_grammar_inducing_Head-blue" alt="Constituency Grammar Inducing Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/abs/2412.10319"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ SCBENCHï¼ˆShared Context BENCHï¼‰æ˜¯ä¸€ä¸ªä¸“ä¸ºè¯„ä¼°é•¿ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®¾è®¡çš„åŸºå‡†æµ‹è¯•.<br>
        â€¢ SCBENCHé‡ç‚¹å…³æ³¨é”®å€¼ï¼ˆKVï¼‰ç¼“å­˜çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬ç”Ÿæˆã€å‹ç¼©ã€æ£€ç´¢å’ŒåŠ è½½å››ä¸ªé˜¶æ®µï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰åŸºå‡†æµ‹è¯•åœ¨å¤šè½®äº¤äº’ä¸­å¯¹KVç¼“å­˜è¯„ä¼°çš„ç©ºç™½.<br>
        â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒæ–¹æ³•åœ¨å¤„ç†ä¸åŒä»»åŠ¡æ—¶å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒåŒæ—¶åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›å’Œç¼“å­˜ä¼˜åŒ–ç­–ç•¥åœ¨å¤æ‚åœºæ™¯ä¸‹å±•ç°å‡ºæ›´å¥½çš„è¡¨ç°.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2015-01-25</td>
      <td style="width: 55%;"><strong>Episodic Memory Benchmark: Episodic Memories Generation and Evaluation Benchmark for Large Language Models</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Syntactic_dependency_Head-blue" alt="Syntactic Dependency Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/abs/2501.13121"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ æ¢è®¨äº†æƒ…æ™¯è®°å¿†åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„é‡è¦æ€§ï¼Œæå‡ºäº†æ„å»ºæ–°åŸºå‡†æµ‹è¯•ä»¥è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›.<br>
        â€¢ ä½œè€…å»ºç«‹äº†ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œè®¾è®¡äº†æ–°çš„ä»»åŠ¡ä¸è¯„ä¼°æ–¹å¼ï¼Œå¼ºè°ƒéœ€è¦æ–°çš„è®­ç»ƒç­–ç•¥æ¥æœ‰æ•ˆæ•´åˆæƒ…èŠ‚è®°å¿†.<br>
        â€¢ Some attention heads track specific syntactic dependencies better than baselines, but no head performs holistic parsing significantly better.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2015-01-03</td>
      <td style="width: 55%;"><strong>LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks</strong></td>
      <td style="width: 15%;">
        <img src="https://img.shields.io/badge/Positional_Head-blue" alt="Positional Head Badge">
        <img src="https://img.shields.io/badge/BPE--merging_Head-blue" alt="BPE-merging Head Badge">
        <img src="https://img.shields.io/badge/Interrogation_Head-blue" alt="Interrogation Head Badge">
      </td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2412.15204"><img src="https://img.shields.io/badge/EMNLP-Paper-%23D2691E" alt="Paper Badge"></a>
        <a href="https://github.com/deep-spin/entmax"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
      </td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ LongBench v2æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£åŠæ¨ç†èƒ½åŠ›çš„å¤šä»»åŠ¡åŸºå‡†.<br>
        â€¢ LongBench v2ç”±503ä¸ªå¤šé¡¹é€‰æ‹©é¢˜æ„æˆï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼Œä¸“æ³¨äºé•¿æ–‡æœ¬çš„ç†è§£ä¸å›ç­”.<br>
        â€¢ ç ”ç©¶å‘ç°æœ€ä¼˜æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶è¡¨ç°ä¼˜äºäººç±»ä¸“å®¶ï¼Œæç¤ºæ¨ç†çš„å¢å¼ºä¸æ—¶é—´è®¡ç®—è§„æ¨¡çš„å…³é”®æ€§.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-10-23</td>
      <td style="width: 55%;"><strong>MADial-Bench Towards real-world evaluation of memory-augmented diglogue generation</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge"></td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/abs/2409.15240"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a>
        <a href="https://github.com/clarkkev/attention-analysis"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
      </td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ MADial-Benchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è®°å¿†å¢å¼ºå¯¹è¯ç”Ÿæˆçš„åŸºå‡†ï¼Œä¸»è¦é’ˆå¯¹å½“å‰å¯¹è¯ç³»ç»Ÿåœ¨é•¿æœŸè®°å¿†æ–¹é¢çš„ä¸è¶³.<br>
        â€¢ MADial-Benchç»“åˆè®¤çŸ¥ç§‘å­¦æ¦‚å¿µï¼Œè¯„ä¼°è®°å¿†æ£€ç´¢ä¸è¯†åˆ«ï¼Œå¹¶å¼•å…¥å¤šå…ƒè¯„åˆ†æ ‡å‡†.<br>
        â€¢ ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æƒ…æ„Ÿæ”¯æŒä¸Šè¡¨ç°è‰¯å¥½ï¼Œè®°å¿†è¯†åˆ«å’Œæ³¨å…¥èƒ½åŠ›ä»éœ€æå‡.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-10-04</td>
      <td style="width: 55%;"><strong>L-CiteEval: A Long-Context Citation Evaluation Benchmark</strong></td>
      <td style="width: 15%;">
        <img src="https://img.shields.io/badge/Positional_Head-blue" alt="Positional Head Badge">
        <img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge">
        <img src="https://img.shields.io/badge/Rare_words_Head-blue" alt="Rare Words Head Badge">
      </td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/pdf/2410.02115"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a>
        <a href="https://github.com/lena-voita/the-story-of-heads"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
      </td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ L-CiteEvalæ˜¯ä¸€ä¸ªé’ˆå¯¹é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆLCMsï¼‰çš„å¤šä»»åŠ¡è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è¡¡é‡è¿™äº›æ¨¡å‹åœ¨ç†è§£å’Œå¼•ç”¨æ–¹é¢çš„èƒ½åŠ›.<br>
        â€¢ è¯¥åŸºå‡†æ¶µç›–11ä¸ªä»»åŠ¡ï¼Œæ”¯æŒ8Kè‡³48Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶æä¾›äº†å…¨é¢çš„è¯„ä¼°æ¡†æ¶.<br>
        â€¢ ç ”ç©¶è¡¨æ˜ï¼Œé—­æºæ¨¡å‹åœ¨å¼•ç”¨è´¨é‡å’Œç”Ÿæˆå‡†ç¡®ç‡ä¸Šä¼˜äºå¼€æºæ¨¡å‹ï¼Œè€Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯èƒ½æœ‰æ•ˆæå‡æ¨¡å‹çš„å¼•ç”¨è´¨é‡.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-08-11</td>
      <td style="width: 55%;"><strong>CAN LONG-CONTEXT LANGUAGE MODELS UNDER-STAND LONG CONTEXTS</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Positional_Head-blue" alt="Positional Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2024.acl-long.859/"><img src="https://img.shields.io/badge/EMNLP-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„èƒ½åŠ›åŠå…¶å±€é™æ€§ï¼Œä»‹ç»äº†GLEåŸºå‡†çš„åˆ›å»ºï¼Œä»¥è¯„ä¼°LLMsåœ¨é•¿æ–‡æœ¬ä¸Šä¸‹æ–‡ç†è§£ä¸­çš„è¡¨ç°.<br>
        â€¢ è®ºæ–‡æè¿°äº†é•¿ä¾èµ–é—®ç­”ä»»åŠ¡çš„æ„å»ºè¿‡ç¨‹å’Œè¯„ä¼°æ ‡å‡†ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒæ¨¡å‹çš„è¡¨ç°.<br>
        â€¢ Lower layers capture syntax, while higher layers encode more semantic information.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-06-19</td>
      <td style="width: 55%;"><strong>LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Retrieval_Head-blue" alt="Retrieval Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/abs/2308.14508"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ LongBenchæ˜¯ä¸€ä¸ªåŒè¯­å¤šä»»åŠ¡åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£ä¸Šçš„èƒ½åŠ›.<br>
        â€¢ è¯¥åŸºå‡†åŒ…å«21ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–å•æ–‡æ¡£é—®ç­”ã€å¤šæ–‡æ¡£é—®ç­”ã€æ‘˜è¦ã€å°‘æ ·æœ¬å­¦ä¹ ã€åˆæˆä»»åŠ¡å’Œä»£ç è¡¥å…¨ç­‰å…­ä¸ªä»»åŠ¡ç±»åˆ«ï¼Œå¹³å‡æ–‡æœ¬é•¿åº¦è¾¾åˆ°6,711ä¸ªå•è¯å’Œ13,386ä¸ªå­—ç¬¦.<br>
        â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡å•†ä¸šæ¨¡å‹ï¼ˆå¦‚GPT-3.5-Turbo-16kï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºå¼€æ”¾æºä»£ç æ¨¡å‹.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-04-16</td>
      <td style="width: 55%;"><strong>HIERARCHICAL CONTEXT MERGING: BETTER LONG CONTEXT UNDERSTANDING FOR PRE-TRAINED LLMS</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Retrieval_Head-blue" alt="Retrieval Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2404.10308"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ HOMERï¼ˆHierarchical cOntext MERgingï¼‰ç®—æ³•æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶çš„å±€é™æ€§.<br>
        â€¢ é€šè¿‡å°†é•¿è¾“å…¥åˆ†å‰²ä¸ºå°å—å¹¶é€å±‚åˆå¹¶ï¼ŒHOMERåœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶æå‡äº†æ¨¡å‹çš„è®°å¿†æ•ˆç‡ä¸æ¨ç†èƒ½åŠ›.<br>
        â€¢ åœ¨å®éªŒä¸­ï¼ŒHOMERåœ¨32Kå’Œ64Kä¸Šä¸‹æ–‡è¾“å…¥ä¸­å±•ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œç»´æŒäº†è¾ƒä½çš„å›°æƒ‘åº¦å’Œå†…å­˜éœ€æ±‚.
      </td>
    </tr>

  </table>

</details>

<details>
  <summary><strong>Systems & Models</strong></summary>

  <table style="width: 100%;">
    <tr>
      <td><strong>Date</strong></td>
      <td><strong>Paper & Summary</strong></td>
      <td><strong>Tags</strong></td>
      <td><strong>Links</strong></td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-11-04</td>
      <td style="width: 55%;"><strong>Memory OS of AI Agent</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://aclanthology.org/2025.emnlp-main.1318.pdf"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ MemoryOSæ—¨åœ¨ä¸ºAIæ™ºèƒ½ä½“å®ç°å…¨é¢ã€é«˜æ•ˆçš„è®°å¿†ç®¡ç†.<br>
        â€¢ MemoryOSä»è®¡ç®—æœºæ“ä½œç³»ç»Ÿçš„å†…å­˜ç®¡ç†åŸç†ä¸­æ±²å–çµæ„Ÿï¼ŒåŒæ—¶å€Ÿé‰´äººè„‘è®°å¿†å­˜å‚¨çš„åˆ†å±‚æœºåˆ¶ï¼Œæ„å»ºäº†ç‹¬ç‰¹çš„æ®µé¡µå¼åˆ†å±‚å­˜å‚¨æ¶æ„ï¼Œå¹¶åŒ…å«å››å¤§æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼šè®°å¿†å­˜å‚¨ã€è®°å¿†æ›´æ–°ã€è®°å¿†æ£€ç´¢ã€å“åº”ç”Ÿæˆ.<br>
        â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒMemoryOS åœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†AIåœ¨é•¿å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§å’Œä¸ªæ€§åŒ–è®°å¿†ä¿ç•™èƒ½åŠ›ï¼Œä¾‹å¦‚åœ¨LoCoMoåŸºå‡†ä¸Šï¼Œæ¨¡å‹çš„F1å’ŒBLEU-1åˆ†æ•°å¹³å‡æå‡äº†49.11%å’Œ46.18%.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-10-08</td>
      <td style="width: 55%;"><strong>A-MEM: Agentic Memory for LLM Agents</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Induction_Head-blue" alt="Induction Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2502.12110"><img src="https://img.shields.io/badge/Anthropic-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ A-Memé€šè¿‡å¼•å…¥Zettelkastenå¼çš„åŠ¨æ€è®°å¿†ç»„ç»‡æœºåˆ¶ï¼Œä¸ºLLMä»£ç†æä¾›äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œé•¿æœŸè®°å¿†â€.<br>
        â€¢ A-Memä¸ä»…èƒ½å­˜å‚¨ä¿¡æ¯ï¼Œè¿˜èƒ½è‡ªæˆ‘é“¾æ¥ã€è‡ªæˆ‘è¿›åŒ–ï¼Œä»è€Œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å–å¾—æ˜¾è‘—ä¼˜åŠ¿.<br>
        â€¢ å®éªŒè¯æ˜ï¼Œå…¶åœ¨æ€§èƒ½ã€æ•ˆç‡å’Œå¯æ‰©å±•æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºæ„å»ºæ›´æ™ºèƒ½ã€æ›´è‡ªä¸»çš„LLMä»£ç†å¥ å®šäº†é‡è¦åŸºç¡€.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-07-04</td>
      <td style="width: 55%;"><strong>MemOS: A Memory OS for AI System</strong></td>
      <td style="width: 15%;">
        <img src="https://img.shields.io/badge/Local_Head-blue" alt="Local Head Badge">
        <img src="https://img.shields.io/badge/Syntactic_Head-blue" alt="Syntactic Head Badge">
        <img src="https://img.shields.io/badge/Delimiter_Head-blue" alt="Delimiter Head Badge">
        <img src="https://img.shields.io/badge/Block_Head-blue" alt="Block Head Badge">
      </td>
      <td style="width: 15%;">
        <a href="https://arxiv.org/abs/2507.03724"><img src="https://img.shields.io/badge/AAAI-Paper-%23D2691E" alt="Paper Badge"></a>
        <a href="https://github.com/iitmnlp/heads-hypothesis"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
      </td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ MemOSï¼ˆMemory Operating Systemï¼‰æ˜¯ä¸€ä¸ªä¸ºAIç³»ç»Ÿè®¾è®¡çš„è®°å¿†æ“ä½œç³»ç»Ÿï¼Œå°†è®°å¿†è§†ä¸ºå¯ç®¡ç†çš„ç³»ç»Ÿèµ„æºï¼Œç»Ÿä¸€äº†æ˜æ–‡ã€åŸºäºæ¿€æ´»çš„å’Œå‚æ•°çº§è®°å¿†çš„è¡¨ç¤ºã€è°ƒåº¦å’Œæ¼”åŒ–ï¼Œå®ç°æˆæœ¬é«˜æ•ˆçš„å­˜å‚¨å’Œæ£€ç´¢.<br>
        â€¢ MemOSé‡‡ç”¨ä¸‰å±‚æ¶æ„ï¼ŒåŒ…æ‹¬æ¥å£å±‚ã€æ“ä½œå±‚å’ŒåŸºç¡€è®¾æ–½å±‚ã€‚æ¥å£å±‚è´Ÿè´£ä¸ç”¨æˆ·æˆ–ä¸Šæ¸¸ç³»ç»Ÿäº¤äº’ï¼Œæä¾›æ ‡å‡†åŒ–çš„è®°å¿†APIï¼›æ“ä½œå±‚è´Ÿè´£ç»„ç»‡å’Œè°ƒåº¦è®°å¿†èµ„æºï¼›åŸºç¡€è®¾æ–½å±‚å¤„ç†è®°å¿†æ•°æ®çš„å­˜å‚¨ã€å®‰å…¨ã€è¿ç§»å’ŒæµåŠ¨.<br>
        â€¢ Memosä¸ºæ¨¡å‹å®ç°è·¨ä»»åŠ¡é€‚åº”ã€è·¨å½¢æ€æ¼”åŒ–ä¸è·¨å¹³å°è¿ç§»æä¾›æ“ä½œç³»ç»Ÿçº§æ”¯æŒã€‚MemOSçš„æå‡ºï¼Œæ ‡å¿—ç€å¤§æ¨¡å‹ä»â€ä»…æ„ŸçŸ¥ä¸ç”Ÿæˆâ€œè¿ˆå‘â€å¯è®°å¿†ä¸è¿›åŒ–â€œçš„å…³é”®è·ƒè¿.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2025-04-28</td>
      <td style="width: 55%;"><strong>Mem0 Building production-ready AI agents with Scalable Long-Term memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Constituency_grammar_inducing_Head-blue" alt="Constituency Grammar Inducing Head Badge"></td>
      <td style="width: 15%;"><a href="https://arxiv.org/pdf/2504.19413"><img src="https://img.shields.io/badge/ACL-Paper-%23D2691E" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ Mem0æ˜¯ä¸€ç§è®°å¿†æ¶æ„ï¼Œå®ƒèƒ½å¤ŸåŠ¨æ€åœ°æå–å’Œæ•´åˆå¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ï¼Œè®© AI ç³»ç»Ÿèƒ½è®°ä½é‡è¦å†…å®¹å¹¶è·¨ä¼šè¯æŒç»­å¯¹è¯.<br>
        â€¢ ä½œè€…è¿˜æå‡ºMem0gï¼Œå®ƒåœ¨ Mem0 çš„åŸºç¡€ä¸ŠåŠ å…¥äº†å›¾ç»“æ„è®°å¿†(å°±æ˜¯çŸ¥è¯†å›¾è°±)ï¼Œä½¿å¾— AI åœ¨å¤„ç†å¤æ‚å…³ç³»æ—¶æ›´å¾—å¿ƒåº”æ‰‹.<br>
        â€¢ NLI tasks increase constituency grammar inducing ability, while SMS tasks decrease it in upper layers.
      </td>
    </tr>
    <tr>
      <td rowspan="2" style="width: 15%;">2024-09-21</td>
      <td style="width: 55%;"><strong>Memory3: Language modeling with explict memory</strong></td>
      <td style="width: 15%;"><img src="https://img.shields.io/badge/Syntactic_dependency_Head-blue" alt="Syntactic Dependency Head Badge"></td>
      <td style="width: 15%;"><a href="https://doi.org/10.4208/jml.240708"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv" alt="Paper Badge"></a></td>
    </tr>
    <tr>
      <td colspan="3">
        â€¢ ä¸€ç§æ–°å‹å¤§å‹è¯­è¨€æ¨¡å‹Memory3ï¼Œå®ƒé€šè¿‡å¼•å…¥æ˜¾å¼è®°å¿†æ¥é™ä½è®­ç»ƒå’Œæ¨ç†æˆæœ¬.<br>
        â€¢ ç ”ç©¶æå‡ºäº†è®°å¿†å›è·¯ç†è®ºï¼Œæè¿°äº†è®°å¿†çš„å¤–éƒ¨åŒ–è¿‡ç¨‹ï¼Œæ˜ç¡®äº†çŸ¥è¯†çš„å®šä¹‰ï¼Œå¼ºè°ƒäº†æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶çš„ä¼˜åŠ¿.<br>
        â€¢ Memory3æœ‰æ•ˆç®¡ç†çŸ¥è¯†å†™å…¥å’Œè¯»å–æˆæœ¬ï¼Œå¹¶é‡‡ç”¨å‹ç¼©æŠ€æœ¯ä½¿å¾—æ˜¾å¼è®°å¿†çš„å­˜å‚¨éœ€æ±‚æ˜¾è‘—é™ä½.
      </td>
    </tr>

  </table>

</details>

## ğŸ§° Resources

### ğŸ“Š Benchmarks and Tasks

|     Edit Type      | Benchmarks \& Datasets                                                  |
| :-----------------------: | ------------------------------------------------------------ |
| **ä¸ªæ€§åŒ–ä»»åŠ¡è¯„ä¼°**  | [IMPLEXCONV](https://aclanthology.org/2025.emnlp-main.580.pdf), [PERSONAMEM](https://arxiv.org/pdf/2504.14225), [PersonaBench](https://aclanthology.org/2025.findings-acl.49.pdf), [PersonaFeedback](https://arxiv.org/pdf/2506.12915), [LaMP](https://aclanthology.org/2024.acl-long.399.pdf)  |
|  **ç»¼åˆæ€§è¯„ä¼°**   | [MemoryAgentBench](https://arxiv.org/pdf/2507.05257) |
|  **è®°å¿†æœºåˆ¶è¯„ä¼°**   | [MemBench](https://aclanthology.org/2025.findings-acl.989.pdf),  [Minerva](https://arxiv.org/pdf/2502.03358)|
|  **é•¿æœŸè®°å¿†è¯„ä¼°**   | [LOCCO](https://aclanthology.org/2025.findings-acl.1014.pdf), [LONGMEMEVAL](https://arxiv.org/pdf/2410.10813), [LOCOMO](https://aclanthology.org/2024.acl-long.747.pdf), [MADial-Bench](https://arxiv.org/abs/2409.15240)|
|  **é•¿å¯¹è¯æ¨æ–­**   | [PREFEVAL](https://arxiv.org/pdf/2502.09597),  [MiniLongBench](https://aclanthology.org/2025.acl-long.560.pdf)|
|  **é•¿ä¸Šä¸‹æ–‡ç†è§£**   | [LongBench V2](https://arxiv.org/pdf/2412.15204), [LongBench](https://arxiv.org/abs/2308.14508) |
|  **é•¿ä¸Šä¸‹æ–‡è¯„ä¼°** |[SCBENCH](https://arxiv.org/abs/2412.10319), [L-CiteEval](https://arxiv.org/pdf/2410.02115), [GLE](https://aclanthology.org/2024.acl-long.859/), [HOMER](https://arxiv.org/pdf/2404.10308) |
|  **é•¿æ–‡æœ¬ç”Ÿæˆ**   | [LongGenBench](https://arxiv.org/pdf/2409.02076) |
|  **æƒ…èŠ‚è®°å¿†è¯„ä¼°**   | [PerLTQA](https://aclanthology.org/2024.sighan-1.18.pdf)|
|  **å¤šæ¨¡æ€è®°å¿†è¯„ä¼°**   | [LOCOMO](https://aclanthology.org/2024.acl-long.747.pdf) |


### ğŸ’» Systems and Open Sources

| System    | Open Sources  | Official Website                 |
|-----------|---------------------------------------------|----------------------------------|
| MemOS     | https://github.com/MemTensor/MemOS          | https://memos.openmem.net/       |
| MemoryOS  | https://github.com/BAI-LAB/MemoryOS         | https://baijia.online/memoryos/  |
| mem0      | https://github.com/mem0ai/mem0              | https://mem0.ai/                 |
| A-mem     | https://github.com/agiresearch/A-mem        | No                               |
| zep       | https://github.com/getzep/zep               | https://www.getzep.com/          |
| Letta     | https://github.com/letta-ai/letta           | No                               |
| memobase  | https://github.com/memodb-io/memobase       | https://www.memobase.io/         |
| Memary    | https://github.com/kingjulio8238/Memary     | No                               |
| memoryOS  | No    | https://memoryos.com/               |


### ğŸ¥ Multi-media resource

| Paper / System | Website Link |
|---------------|--------------|
| **MemOS** | https://www.youtube.com/watch?v=R3v0fnqC5H8<br>https://www.bilibili.com/video/BV1PBuyzBENt |
| **mem0** | https://www.youtube.com/watch?v=jbc-N4_D-k0 |
| **A-mem** | https://www.youtube.com/watch?v=49ERSQeHC-Y<br>https://www.youtube.com/watch?v=ZYz_UpjEut8 |
| **zep** | https://www.youtube.com/watch?v=kNsX2qu8jHY |
| **Letta** | https://www.youtube.com/watch?v=MK3H_Y-l4QU |
| **memobase** | https://www.youtube.com/watch?v=HNGhjojsCpQ |



## ğŸ¤  Make a Contribution
Issue Template: 
```
Title: [paper's title]
Head: [head name1] (, [head name2] ...)
Published: [arXiv / ACL / ICLR / NIPS / ...]
Summary:
  - Innovation:
  - Tasks:
  - Significant Result: 
```

## ğŸŒŸ Star Trends

<a href="https://star-history.com/#IAAR-Shanghai/Awesome-AI-Memory&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=IAAR-Shanghai/Awesome-AI-Memory&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=IAAR-Shanghai/Awesome-AI-Memory&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=IAAR-Shanghai/Awesome-AI-Memory&type=Date" />
  </picture>
</a>

